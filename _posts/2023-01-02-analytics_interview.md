# Analytics in Silicon Valley: Preparing for the Interview ("The Gauntlet")

As many of you know who have followed my journey over the last year or so, I've wholeheartedly dedicated myself to learning and practicing Data Science.  This learning journey has contributed to my ability to land a dream role at a dream company, as an Insights Analyst at LinkedIn.  First thing I will say is, yes... all of the effort was absolutely worth it.

If you are in the position that I recently was, trying to break into analytics, and particularly trying to do so in Silicon Valley/ San Francisco Bay Area, you MUST prepare for these interviews.  They are not easy.  However, I've curated a list of some of the most common/crucial and more technical questions (respectively)  I came across interviewing from roles spanning Product Analysis, Data Analysis, Data Science, Quantitative Analysis, Business Intelligence and others.  Think through these and be sure you can nail both.

## Common (and Crucial) Questions

### Question 1: Tell me about yourself

I put this question as number one very intentionally, because it's IMPORTANT to practice, and quite literally, it's the first question you will get in most interviews.  It's amazing how difficult it is to have a cohesive answer to this question without thinking about it in advance.  HINT: Don't fill the time with anecdotes and discussion of your hobbies.  Talk through your resume (from your current/ most recent role backwards) and how your experiences lend themselves to you being a good asset for the role.  Cap off your response with a small blurb about who you are outside of work, but don't make that the focal point.  Practice and record yourself to ensure you sound like somebody that you would hire.  Be genuine and strategic at the same time.

### Question 2: Tell me about an analysis that you did that impacted a business decision

This question came up AGAIN and AGAIN throughout my interviews and you must be prepared to answer this if you want a job in analytics.  If you're like me, and you've been in a situation where there wasn't always a strong feedback loop in terms of the impact your analyses were making, I encourage either finding projects where you can quantify the results, or circling back to the stakeholders you worked with prior and figuring out the impact of some of your efforts.  Focus on the RESULT, a QUANTIFIED IMPACT.

### Question 3: What are some of the metrics do you track and how are they calculated? 

This is another question that seemed to come up quite a bit. What the interviewer is generally looking for is your ability to explain a calculation.  It doesn't help to be able to say you measured "customer engagement" without being able to explain how it's done, why it's done that way, and better yet, some of the tradeoffs involved in choosing to calculate it your way compared to other ways it could be accomplished. The most important thing to prepare here is to take inventory of what you've done and be able to speak intelligently about it.

### Question 4: Tell me about a challenge you've faced with collaboration (missing shared vision, geographical challenges, etc.) and how did you overcome the challenge?

Of all the "tell me about a time" questions you'll likely encounter, one of the more challenging (yet common) ones to come up is this one.  As you might guess, your answer demonstrates your ability to not only overcome some level of adversity, but to be able to move a project forward by overcoming the challenges you are presented with. You should speak to how you navigate difficult conversations, align across geographies, etc.  Of course, with a question there isn't a technically "correct" answer.  We are all human, our experiences are different, and the way we handle situations are unique.

### Question 5: What's the most difficult analysis you've ever done?

Another seemingly simple question requiring a bit of a complex answer.  And the answer, similarly, requires  you to make the complex simple.  You've probably heard the saying "you don't really understand something until you can explain it to a kindergartener." The goal in answering this question is being able to thoroughly break down both the problem and  your solution.  This includes both your thought process and the technical aspects; you'll be even better off if you can explain the alternatives including their costs and benefits.


## Technical Questions

### Question 1. Multi-Part Dice Game Statistics 

Part I: We are going to play a dice game.  Here are the rules.  You're going to roll one six-sided die, and  I will pay you the dollar amount that matches the value on the die (1 = $1, 2 = $2, 3 = $3, you get the idea).  If you roll the die one time, what are your expected winnings
  
Part II: Now that you've rolled the die one time, I'm going to give you the OPTION for a second roll.  At what value of the first roll would you want to roll a second time? What are your new expected winnings for a two-roll game? HINT: NOT THE SAME AS FOR ONE ROLL
  
Part III: I'm now going to give you the OPTION for a third roll.  How does your strategy change?  What are your new expected winnings for a three-roll game?  HINT: AGAIN, NOT THE SAME AS THE PRIOR TWO GAMES
  
THE ANSWERS TO THE ABOVE QUESTIONS CAN BE FOUND HERE: https://math.stackexchange.com/questions/179534/the-expected-payoff-of-a-dice-game. 


### Question 2: In a classification problem, is it better to have incorrectly positively identified something, or better to have negatively identified something.

This question came up quite a bit for the more technical roles, and you should be able to lay out a general understanding of a confusion matrix and which type of misclassification is preferable.  For those not familiar with the concept, it's best understood in the context of an example.  Imagine you are a doctor who is responsible for diagnosing cancer, and for each cancer diagnosis, the patient will undergo additional testing.  Is it more problematic to diagnose somebody with cancer who doesn't have it, or to diagnose somebody with no cancer who does have it.  There are pros and cons to each side, but I believe it a more costly error to tell somebody they don't have cancer and they miss the opportunity for additional testing than sending somebody for the additional testing who may not need it.   Because no model is perfect, somebody who works on classification problems will always have to think of these trade-offs and pick the "lesser of two evils."

### Question 3:
